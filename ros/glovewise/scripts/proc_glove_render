#!/usr/bin/env python3

import sys
sys.path.append("/usr/lib/python3/dist-packages")

print("load libraries")
if 1:
    import glovewise
    import cv_bridge
    import cv2
    import numpy as np
    import tractor as tr
    import tractor.types_double as tt
    import yaml
    import mittenwire
    import rospkg
    import rosbag


print("load multicam")
multicam = glovewise.MultiCameraModel.load(sys.argv[1])

print("load glove model")
glove_model = glovewise.GloveModel()
glove_model.load_resource("glovewise", "/models/bonehand37s.dae")

bridge = cv_bridge.CvBridge()
motion_solver = glovewise.MotionSolver(glove_model, multicam)
robot_model = motion_solver.robot_model


def imshow(img):
    cv2.imshow("images", img)
    k = cv2.waitKey(0)
    if k > 0:
        print(k)
        if k == 27 or k == 113:
            exit(0)


glove_renderer = glovewise.GloveRenderer(glove_model)

for bag_path in sys.argv[2:]:

    solve_path = glovewise.extpath(bag_path, ".solve.yaml")
    with open(solve_path, "r") as f:
        solve_data = yaml.load(f, Loader=yaml.CLoader)

    tstart = solve_data[0]["time"]
    tend = solve_data[-1]["time"]

    solve_data = dict(zip(
        [x["time"] for x in solve_data],
        solve_data
    ))

    outpath = glovewise.extpath(bag_path, ".render.bag")
    outbag = rosbag.Bag(outpath, "w")

    for image_set in glovewise.ImageBag(bag_path):
        current_time = image_set.time.to_sec()

        print((current_time - tstart) * 100 / (tend - tstart))

        images = [bridge.compressed_imgmsg_to_cv2(
            image_set.images[image_index].image, "bgr8") for image_index in range(len(image_set.images))]

        if current_time not in solve_data:
            continue
        else:
            solve_frame = solve_data[current_time]

            profile = 0

            with glovewise.Profiler("deserialize", profile):
                joint_states = tt.JointStates(robot_model)
                joint_states.deserialize([tt.Scalar(solve_frame["joints"][n])
                                          for n in robot_model.variable_names])

            with glovewise.Profiler("linkstates", profile):
                link_states = motion_solver.glove_ik.compute_link_states(
                    joint_states)

            with glovewise.Profiler("render", profile):
                for iimg in range(len(image_set.images)):
                    camera = multicam.camera_map[image_set.images[iimg].name]
                    mask = glove_renderer.render_mask(camera, link_states, (
                        images[iimg].shape[1],
                        images[iimg].shape[0]
                    ), image_set.images[iimg].info.roi)

                    images[iimg][:, :, 0] = mask

        for iimg in range(len(image_set.images)):
            image = image_set.images[iimg]
            outbag.write(image.name, bridge.cv2_to_compressed_imgmsg(
                images[iimg]), image.image.header.stamp)

    outbag.close()

    print("ready", outpath)
