#!/usr/bin/env python3

import sys
sys.path.append("/usr/lib/python3/dist-packages")

print("load libraries")
if 1:
    import glovewise
    import cv_bridge
    import cv2
    import numpy as np
    import tractor as tr
    import tractor.types_double as tt
    import yaml
    import sklearn
    import sklearn.decomposition
    import mittenwire
    import bson

print("load glove model")
glove_model = glovewise.GloveModel()
glove_model.load_resource("glovewise", "/models/bonehand37.dae")

bridge = cv_bridge.CvBridge()
tac_layout = glovewise.TactileLayout()
tac_renderer = glovewise.TactileRenderer()
robot_model = tt.RobotModel(glove_model.build_urdf(), "")


for bag_path in sys.argv[1:]:

    tac_seq = glovewise.TactileSequence.load(bag_path).process()

    print("loading object features")

    obj_path = glovewise.extpath(bag_path, ".track.bson")
    with mittenwire.Profiler("load bson"):
        with open(obj_path, "rb") as f:
            obj_data = bson.loads(f.read())

    obj_data = obj_data["object_feature_sequence"]
    object_feature_positions = {}
    object_feature_descriptors = {}
    object_feature_visibility = {}
    for obj_frame in obj_data:
        t = obj_frame["time"]
        object_feature_positions[t] = [glovewise.dict2point(
            f["position"]) for f in obj_frame["features"]]
        object_feature_descriptors[t] = [f["descriptor"]
                                         for f in obj_frame["features"]]
        object_feature_visibility[t] = [f["active"]
                                        for f in obj_frame["features"]]
    all_object_feature_descriptors = [
        i for o in object_feature_descriptors.values() for i in o]
    print("fit object feature pca")
    object_feature_pca = sklearn.decomposition.PCA(n_components=3)
    object_feature_pca.fit(all_object_feature_descriptors)

    print("glove")
    solve_path = glovewise.extpath(bag_path, ".solve.yaml")
    with open(solve_path, "r") as f:
        solve_data = yaml.load(f, Loader=yaml.CLoader)

    viz_path = glovewise.extpath(bag_path, ".viz.bag")
    vizbag = glovewise.VizBag.create(viz_path)

    print("solve_path", solve_path)
    print("solve_data", solve_data)

    tstart = solve_data[0]["time"]
    tend = solve_data[-1]["time"]

    tac_interp = glovewise.TactileInterpolator(tac_seq, tstart, tend)

    print("visualize trajectory")
    for solve_frame in solve_data:

        current_time = solve_frame["time"]

        print((current_time - tstart) * 100 / (tend - tstart))

        profile = 0

        vizbag.begin_frame(current_time)

        if current_time in object_feature_positions:
            visibility = object_feature_visibility[current_time]
            positions = object_feature_positions[current_time]
            descriptors = object_feature_descriptors[current_time]
            if len(descriptors):
                colors = object_feature_pca.transform(descriptors)
                colors -= np.min(colors)
                colors /= np.max(colors)
                colors = np.hstack([colors, np.ones([colors.shape[0], 1])])
                for i in range(len(positions)):
                    if not visibility[i]:
                        colors[i] = [1, 0, 0, 1]
                vizbag.visualize_colored_points(
                    "object_features", 0.01, colors, positions)

        with glovewise.Profiler("deserialize", profile):
            joint_states = tt.JointStates(robot_model)
            joint_states.deserialize([tt.Scalar(solve_frame["joints"][n])
                                      for n in robot_model.variable_names])

        with glovewise.Profiler("linkstates", profile):
            link_states = robot_model.forward_kinematics(joint_states)

        with glovewise.Profiler("blend", profile):
            vertices = glove_model.blend_skin_from_link_states(link_states)

        with glovewise.Profiler("tac interpolate", profile):
            tac = tac_interp.interpolate(current_time)
            tac = tac_layout.map_matrix(tac)

        with glovewise.Profiler("render write tac image", profile):
            image = tac_renderer.render_smooth_image(tac)
            msg = bridge.cv2_to_compressed_imgmsg(image)
            vizbag.insert_message("/tacviz", msg, current_time)

        with glovewise.Profiler("render glove tac matrix", profile):
            image = cv2.resize(
                tac, (tac.shape[1] * 20, tac.shape[0] * 20), interpolation=cv2.INTER_CUBIC)
            image[image < 0] = 0
            image *= 1.5
            colors = np.zeros([image.shape[0], image.shape[1], 4])
            colors[:, :, 0] = image * 4
            colors[:, :, 1] = image * 2
            colors[:, :, 2] = image * 1
            colors[:, :, 3] = 1
            colors = np.array(colors, np.float32)

        with glovewise.Profiler("write_img", profile):
            msg = bridge.cv2_to_imgmsg(colors)
            vizbag.insert_message("/tacc", msg, current_time)

        with glovewise.Profiler("build vertex colors", profile):
            mesh_colors = glove_model.build_tactile_colors(colors)

        with glovewise.Profiler("write mesh", profile):
            vizbag.visualize_colored_mesh_fast(
                "glove", current_time, "glove", mesh_colors, vertices)

    print("write vizbag")
    vizbag.write()

    print("finished", viz_path)
